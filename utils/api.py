import requests
import streamlit as st
import time
import logging
import os
import json
import traceback
import re
from utils.config import CONFIG

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LLMClient:
    """å¤§è¯­è¨€æ¨¡å‹APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        # ä»é…ç½®æ–‡ä»¶è¯»å–è®¾ç½®
        api_config = CONFIG["api"]
        self.endpoint = api_config["endpoint"]
        self.max_retries = api_config["max_retries"]
        self.retry_delay = api_config["retry_delay"]
        self.base_timeout = api_config["timeout"]
        self.session = requests.Session()  # ä½¿ç”¨ä¼šè¯ä¿æŒè¿æ¥
        self.available_models = self._get_available_models()
        logger.info(f"åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ŒAPIç«¯ç‚¹: {self.endpoint}")
        logger.info(f"å¯ç”¨æ¨¡å‹: {', '.join(self.available_models) if self.available_models else 'æ— '}")

    def _get_available_models(self):
        """è·å–APIå¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        try:
            # æ£€æŸ¥APIç±»å‹
            api_type = self._detect_api_type()
            
            # æ ¹æ®APIç±»å‹è·å–æ¨¡å‹åˆ—è¡¨
            if api_type == "ollama":
                # Ollama APIä½¿ç”¨å•ç‹¬çš„ç«¯ç‚¹è·å–æ¨¡å‹åˆ—è¡¨
                models_endpoint = self.endpoint.replace("/api/chat", "/api/tags")
                if models_endpoint == self.endpoint:
                    models_endpoint = "http://localhost:1314/api/tags"  # ä½¿ç”¨1314ç«¯å£
                
                try:
                    response = self.session.get(models_endpoint, timeout=self.base_timeout)
                    if response.status_code == 200:
                        data = response.json()
                        if "models" in data:
                            return [model['name'] for model in data['models']]
                except requests.exceptions.RequestException as e:
                    logger.warning(f"è¿æ¥åˆ°Ollama APIå¤±è´¥: {e}ï¼Œä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹åˆ—è¡¨")
                    # è¿”å›å›ºå®šçš„æ¨¡å‹åˆ—è¡¨
                    return ["qwen2.5:3b", "deepseek-r1:8b", "llama3.1:latest"]
            
            # é»˜è®¤è¿”å›config.jsonä¸­å®šä¹‰çš„æ¨¡å‹
            return list(CONFIG.get("models", {}).keys())
        except Exception as e:
            logger.warning(f"è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            # ç¡®ä¿è¿”å›å½“å‰å·²çŸ¥å¯ç”¨çš„æ¨¡å‹
            return ["qwen2.5:3b", "deepseek-r1:8b", "llama3.1:latest"]  # è¿”å›å›ºå®šæ¨¡å‹åˆ—è¡¨ä½œä¸ºå¤‡é€‰

    def generate_response(self, messages, model="llama3", temperature=0.7, max_tokens=2048, stream=True):
        """ç”ŸæˆAIå›å¤ï¼Œæ·»åŠ é‡è¯•æœºåˆ¶ï¼Œæ”¯æŒæµå¼è¾“å‡º"""
        # è®°å½•è¯·æ±‚å¼€å§‹
        logger.info(f"å¼€å§‹è¯·æ±‚æ¨¡å‹ {model}ï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
        
        # å‡†å¤‡APIå¯†é’¥å’Œè¯·æ±‚å¤´
        headers = {"Content-Type": "application/json"}
        
        # æ£€æŸ¥APIç±»å‹
        api_type = self._detect_api_type()
        logger.info(f"æ£€æµ‹åˆ°APIç±»å‹: {api_type}")
        
        # éªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™åˆ‡æ¢åˆ°é»˜è®¤æ¨¡å‹
        model = self._validate_model(model)
        
        # æ ¹æ®APIç±»å‹å‡†å¤‡è¯·æ±‚æ•°æ®
        if api_type == "ollama":
            data = self._prepare_ollama_request(messages, model, temperature, max_tokens, stream)
        elif api_type == "openai":
            data = self._prepare_openai_request(messages, model, temperature, max_tokens, stream)
            api_key = os.environ.get("OPENAI_API_KEY", "")
            if api_key:
                headers["Authorization"] = f"Bearer {api_key}"
            else:
                logger.warning("ä½¿ç”¨OpenAI APIä½†æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        else:
            # é»˜è®¤æ ¼å¼
            data = {
                "model": model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": stream
            }
        
        # è®°å½•è¯¦ç»†çš„è¯·æ±‚ä¿¡æ¯
        logger.info(f"APIè¯·æ±‚è¯¦æƒ…: endpoint={self.endpoint}, model={model}, stream={stream}, temperature={temperature}, max_tokens={max_tokens}")
        
        # é‡è¯•é€»è¾‘
        for attempt in range(self.max_retries):
            try:
                # è®¡ç®—å½“å‰å°è¯•çš„è¶…æ—¶æ—¶é—´ï¼ˆé€æ¸å¢åŠ ï¼‰
                current_timeout = self.base_timeout * (1 + attempt * 0.5)
                logger.info(f"å°è¯• #{attempt+1}/{self.max_retries}, è®¾ç½®è¶…æ—¶: {current_timeout}ç§’")
                
                # å‘é€è¯·æ±‚
                # ä½¿ç”¨ (connect_timeout, read_timeout) æ–¹å¼ï¼Œé¿å…åœ¨é•¿æ—¶é—´æµå¼è¯»å–æ—¶æ— é™é˜»å¡
                connect_timeout = min(10, current_timeout)
                read_timeout = max(30, current_timeout)
                response = self.session.post(
                    self.endpoint,
                    headers=headers,
                    json=data,
                    timeout=(connect_timeout, read_timeout)
                )
                
                # è®°å½•å“åº”çŠ¶æ€
                logger.info(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                response.raise_for_status()
                
                # å¦‚æœæ˜¯æµå¼è¾“å‡º
                if stream:
                    # è¿”å›å®Œæ•´å›å¤å­—ç¬¦ä¸²å’Œé”™è¯¯ä¿¡æ¯
                    return self._handle_streaming_response(response, api_type), None
                else:
                    # å¤„ç†æ­£å¸¸JSONå“åº”
                    resp_data = response.json()
                    logger.info(f"æ”¶åˆ°JSONå“åº”")
                    
                    # æ ¹æ®ä¸åŒAPIæ ¼å¼æå–å†…å®¹
                    content = self._extract_content_from_response(resp_data, api_type)
                    return content, None
                
            except requests.exceptions.Timeout:
                logger.warning(f"è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt+1}/{self.max_retries})")
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…åé‡è¯•
                if attempt < self.max_retries - 1:
                    sleep_time = self.retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                    time.sleep(sleep_time)
                else:
                    return "", "è¯·æ±‚è¶…æ—¶ï¼ŒæœåŠ¡å™¨æœªå“åº”"
            
            except requests.exceptions.HTTPError as e:
                status_code = e.response.status_code
                logger.error(f"HTTPé”™è¯¯: {status_code}, {e}")
                
                # è®°å½•å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
                try:
                    error_content = e.response.text
                    logger.error(f"é”™è¯¯å“åº”å†…å®¹: {error_content[:500]}")
                except:
                    logger.error("æ— æ³•è¯»å–é”™è¯¯å“åº”å†…å®¹")
                
                # æ ¹æ®çŠ¶æ€ç å¤„ç†ä¸åŒé”™è¯¯
                if status_code == 429:  # è¿‡å¤šè¯·æ±‚
                    if attempt < self.max_retries - 1:
                        sleep_time = self.retry_delay * (2 ** attempt)
                        time.sleep(sleep_time)
                    else:
                        return "", "æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åå†è¯•"
                elif status_code == 401:  # æœªæˆæƒ
                    return "", "APIå¯†é’¥æ— æ•ˆæˆ–ä¸æ­£ç¡®"
                elif status_code == 404:  # èµ„æºä¸å­˜åœ¨
                    return "", f"æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨ï¼Œè¯·ç¡®ä¿OllamaæœåŠ¡å·²å¯åŠ¨å¹¶åœ¨ç«¯å£1314è¿è¡Œ"
                else:
                    return "", f"HTTPé”™è¯¯ {status_code}: {e}"
            
            except requests.exceptions.ConnectionError as e:
                logger.error(f"è¿æ¥é”™è¯¯: {e}")
                if attempt < self.max_retries - 1:
                    sleep_time = self.retry_delay * (2 ** attempt)
                    logger.info(f"ç­‰å¾… {sleep_time}ç§’åé‡è¯•...")
                    time.sleep(sleep_time)
                else:
                    # å°è¯•ä½¿ç”¨å¤‡ç”¨ç«¯ç‚¹
                    backup_result = self._try_backup_endpoint(messages, model, temperature, max_tokens)
                    if backup_result:
                        return backup_result, None
                    return "", f"è¿æ¥é”™è¯¯: æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨ ({self.endpoint})ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡æ˜¯å¦è¿è¡Œ"
            
            except Exception as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}", exc_info=True)
                return "", f"è¯·æ±‚å‡ºé”™: {str(e)}"
    
    def _validate_model(self, model):
        """éªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼Œä¸å¯ç”¨æ—¶è¿”å›å¤‡é€‰æ¨¡å‹"""
        if not self.available_models or model in self.available_models:
            return model
            
        # å¦‚æœæŒ‡å®šçš„æ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•æ‰¾åˆ°åŒ¹é…å‰ç¼€çš„æ¨¡å‹
        model_prefix = model.split(':')[0]
        for available_model in self.available_models:
            if available_model.startswith(model_prefix):
                logger.warning(f"æŒ‡å®šçš„æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° {available_model}")
                return available_model
                
        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„æ¨¡å‹ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
        if self.available_models:
            logger.warning(f"æŒ‡å®šçš„æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° {self.available_models[0]}")
            return self.available_models[0]
            
        # å¦‚æœæ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¿”å›åŸå§‹æ¨¡å‹ï¼ˆå¯èƒ½ä¼šå¯¼è‡´é”™è¯¯ï¼‰
        return model
    
    def _try_backup_endpoint(self, messages, model, temperature, max_tokens):
        """å°è¯•ä½¿ç”¨å¤‡ç”¨APIç«¯ç‚¹"""
        try:
            logger.info("å°è¯•ä½¿ç”¨å¤‡ç”¨APIç«¯ç‚¹")
            # æ„å»ºç®€å•çš„å“åº”
            important_content = self._extract_important_content(messages[-1]["content"])
            return f'æ— æ³•è¿æ¥åˆ°APIæœåŠ¡ã€‚æ‚¨çš„é—®é¢˜æ˜¯å…³äºï¼š"{important_content}"ã€‚è¯·æ£€æŸ¥APIæœåŠ¡æ˜¯å¦è¿è¡Œã€‚'
        except Exception as e:
            logger.error(f"ä½¿ç”¨å¤‡ç”¨ç«¯ç‚¹å¤±è´¥: {e}")
            return None
            
    def _extract_important_content(self, text):
        """ä»æ–‡æœ¬ä¸­æå–é‡è¦å†…å®¹"""
        # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥è¿”å›
        if len(text) < 100:
            return text
            
        # å¦åˆ™æå–å‰100ä¸ªå­—ç¬¦
        return text[:100] + "..."
    
    def generate_stream(self, messages, model="llama3", temperature=0.7, max_tokens=2048):
        """ç”Ÿæˆæµå¼å“åº”ï¼Œç›´æ¥è¿”å›ç”Ÿæˆå™¨ï¼Œä¾›å‰ç«¯å¤„ç†"""
        # è®°å½•è¯·æ±‚å¼€å§‹
        logger.info(f"å¼€å§‹æµå¼è¯·æ±‚æ¨¡å‹ {model}ï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
        
        # å‡†å¤‡APIå¯†é’¥å’Œè¯·æ±‚å¤´
        headers = {"Content-Type": "application/json"}
        
        # æ£€æŸ¥APIç±»å‹
        api_type = self._detect_api_type()
        logger.info(f"æ£€æµ‹åˆ°APIç±»å‹: {api_type}")
        
        # éªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨
        model = self._validate_model(model)
        
        # è®°å½•è¯¦ç»†æ—¥å¿—
        logger.info(f"ä½¿ç”¨APIç«¯ç‚¹: {self.endpoint}")
        
        # æ ¹æ®APIç±»å‹å‡†å¤‡è¯·æ±‚æ•°æ®
        if api_type == "ollama":
            data = self._prepare_ollama_request(messages, model, temperature, max_tokens, True)
        elif api_type == "openai":
            data = self._prepare_openai_request(messages, model, temperature, max_tokens, True)
            api_key = os.environ.get("OPENAI_API_KEY", "")
            if api_key:
                headers["Authorization"] = f"Bearer {api_key}"
        else:
            # é»˜è®¤æ ¼å¼
            data = {
                "model": model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": True
            }
        
        # æœ€å¤§é‡è¯•æ¬¡æ•°
        for attempt in range(self.max_retries):
            try:
                # è®°å½•å°è¯•ä¿¡æ¯
                logger.info(f"å°è¯• #{attempt+1}/{self.max_retries} è¿æ¥åˆ° {self.endpoint}")
                
                # è®¡ç®—å½“å‰å°è¯•çš„è¶…æ—¶æ—¶é—´
                current_timeout = self.base_timeout * (1 + attempt * 0.5)
                
                # å‘é€è¯·æ±‚å‰å…ˆç¡®è®¤è¯·æ±‚çš„ä¿¡æ¯
                logger.info(f"è¯·æ±‚æ•°æ®: model={model}, temperature={temperature}, max_tokens={max_tokens}")
                
                # å‘é€è¯·æ±‚ï¼šä½¿ç”¨ (connect_timeout, read_timeout) å…ƒç»„ä»¥é¿å…åœ¨æµå¼è¯»å–æ—¶é•¿æ—¶é—´é˜»å¡
                # å¯¹äºæµå¼è¯·æ±‚ï¼Œä½¿ç”¨ä¸“é—¨çš„å¯é…ç½® read timeoutï¼ˆé»˜è®¤æ›´ä¿å®ˆçš„20ç§’ï¼‰ä»¥ä¾¿åœ¨æœåŠ¡è¿”å›éåˆ†å—å“åº”æ—¶èƒ½æ›´å¿«å›é€€
                connect_timeout = min(10, current_timeout)
                stream_read_timeout = CONFIG.get("api", {}).get("stream_read_timeout", 20)
                # ä¿è¯ read_timeout ä¸å°äºå½“å‰è®¡ç®—å€¼çš„ä¸€éƒ¨åˆ†ï¼Œä»¥é¿å…è¿‡æ—©è¶…æ—¶
                read_timeout = max(stream_read_timeout, current_timeout)
                response = self.session.post(
                    self.endpoint,
                    headers=headers,
                    json=data,
                    timeout=(connect_timeout, read_timeout),
                    stream=True
                )
                
                # è®°å½•å“åº”ä¿¡æ¯
                logger.info(f"æ”¶åˆ°å“åº”ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                response.raise_for_status()
                
                # è·å–æµå¼å“åº”çš„è¿­ä»£å™¨
                line_iterator = response.iter_lines()
                
                # æ ‡è®°æ˜¯å¦æ”¶åˆ°ä»»ä½•å†…å®¹
                received_content = False

                # å¤„ç†æµå¼å“åº”ï¼ˆæŒ‰è¡Œè¿­ä»£ï¼‰
                try:
                    for line in line_iterator:
                        if not line:
                            continue

                        # è§£ææ•°æ®è¡Œ
                        if line.startswith(b'data: '):
                            data_text = line[6:].decode('utf-8', errors='replace')

                            if data_text.strip() == "[DONE]":
                                logger.info("æ”¶åˆ°æµç»“æŸæ ‡è®° [DONE]")
                                break

                            # å°è¯•è§£æJSON
                            try:
                                chunk = json.loads(data_text)

                                # æ ¹æ®ä¸åŒAPIç±»å‹æå–å†…å®¹
                                content = None
                                if api_type == "ollama":
                                    if "message" in chunk and "content" in chunk["message"]:
                                        content = chunk["message"]["content"]
                                    elif "response" in chunk:
                                        content = chunk["response"]
                                elif api_type == "openai":
                                    if "choices" in chunk and len(chunk["choices"]) > 0:
                                        delta = chunk["choices"][0].get("delta", {})
                                        content = delta.get("content", "")
                                else:
                                    # é€šç”¨æ ¼å¼è§£æ
                                    content = self._extract_stream_chunk(chunk)

                                if content:
                                    received_content = True
                                    yield content
                            except json.JSONDecodeError:
                                logger.warning(f"JSONè§£æå¤±è´¥: {data_text[:100]}")
                            except Exception as e:
                                logger.error(f"å¤„ç†æ•°æ®å—æ—¶å‡ºé”™: {e}")
                                logger.error(traceback.format_exc())
                        else:
                            # å¤„ç†æ²¡æœ‰data:å‰ç¼€çš„è¡Œ
                            try:
                                line_text = line.decode('utf-8', errors='replace')

                                # å°è¯•è§£æéæ ‡å‡†è¡Œä¸ºJSON
                                try:
                                    chunk = json.loads(line_text)
                                    content = self._extract_stream_chunk(chunk)
                                    if content:
                                        received_content = True
                                        yield content
                                except json.JSONDecodeError:
                                    # ä¸æ˜¯JSONï¼Œå¯èƒ½æ˜¯æ™®é€šæ–‡æœ¬
                                    if line_text and not line_text.startswith("{") and not line_text.startswith("["):
                                        received_content = True
                                        yield line_text
                            except Exception as e:
                                logger.error(f"å¤„ç†éæ ‡å‡†è¡Œæ—¶å‡ºé”™: {e}")
                except requests.exceptions.ChunkedEncodingError as e:
                    # åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œresponse.iter_lines() å¯èƒ½æŠ›å‡ºåˆ†å—ç¼–ç é”™è¯¯ï¼Œè®°å½•å¹¶ç»§ç»­å°è¯•å›é€€æ–¹æ¡ˆ
                    logger.warning(f"è¯»å–æµå¼å“åº”æ—¶å‡ºç°åˆ†å—ç¼–ç é”™è¯¯: {e}")

                # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•åˆ†å—å†…å®¹ï¼Œå°è¯•å›é€€ï¼šè¯»å–å®Œæ•´å“åº”ä½“å¹¶è§£æJSONæˆ–ä½œä¸ºçº¯æ–‡æœ¬è¿”å›
                if not received_content:
                    try:
                        raw = response.content
                        if raw:
                            text = raw.decode('utf-8', errors='replace')
                            # å°è¯•è§£æä¸ºJSON
                            try:
                                resp = json.loads(text)
                                content = self._extract_content_from_response(resp, api_type)
                                if content:
                                    yield content
                                else:
                                    logger.warning("å›é€€è§£æï¼šè§£æåˆ°JSONä½†æ— æ³•æå–å†…å®¹ï¼Œè¿”å›åŸå§‹æ–‡æœ¬æ‘˜è¦")
                                    yield text
                            except json.JSONDecodeError:
                                # ä¸æ˜¯JSONï¼Œç›´æ¥ä½œä¸ºçº¯æ–‡æœ¬è¿”å›ï¼ˆtrimï¼‰
                                logger.info("å›é€€è§£æï¼šå“åº”ä¸æ˜¯JSONï¼Œä½œä¸ºçº¯æ–‡æœ¬è¿”å›")
                                yield text
                        else:
                            logger.warning("ä»APIæ¥æ”¶åˆ°å“åº”ï¼Œä½†æ—¢æ²¡æœ‰æµå¼åˆ†å—ä¹Ÿæ²¡æœ‰ä¸»ä½“å†…å®¹")
                            yield "æœªèƒ½ä»æ¨¡å‹è·å–æœ‰æ•ˆå“åº”"
                    except Exception as e:
                        logger.error(f"å›é€€è§£æå“åº”æ—¶å‡ºé”™: {e}")
                        yield "å¤„ç†å“åº”æ—¶å‡ºé”™"
                
                # æˆåŠŸå®Œæˆç”Ÿæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                break
                
            except requests.exceptions.ConnectionError as e:
                logger.error(f"è¿æ¥é”™è¯¯: {e}")
                if attempt < self.max_retries - 1:
                    sleep_time = self.retry_delay * (2 ** attempt)
                    logger.info(f"ç­‰å¾… {sleep_time}ç§’åé‡è¯•...")
                    time.sleep(sleep_time)
                else:
                    error_msg = f"æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨ ({self.endpoint})ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡æ˜¯å¦è¿è¡Œ"
                    logger.error(error_msg)
                    yield error_msg
            except Exception as e:
                logger.error(f"æµå¼ç”Ÿæˆå‡ºé”™: {e}")
                logger.error(traceback.format_exc())
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * (2 ** attempt))
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¿”å›é”™è¯¯æ¶ˆæ¯
                    error_msg = f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
                    logger.error(error_msg)
                    yield error_msg
    
    def _detect_api_type(self):
        """æ£€æµ‹APIç±»å‹"""
        if "ollama" in self.endpoint:
            return "ollama"
        elif "openai.com" in self.endpoint:
            return "openai"
        else:
            return "unknown"
    
    def _prepare_ollama_request(self, messages, model, temperature, max_tokens, stream):
        """å‡†å¤‡Ollama APIè¯·æ±‚æ ¼å¼"""
        return {
            "model": model,
            "messages": messages,
            "stream": stream,
            "options": {
                "temperature": temperature,
                "num_predict": max_tokens
            }
        }
    
    def _prepare_openai_request(self, messages, model, temperature, max_tokens, stream):
        """å‡†å¤‡OpenAI APIè¯·æ±‚æ ¼å¼"""
        return {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream
        }
    
    def _extract_content_from_response(self, response_data, api_type):
        """ä»ä¸åŒAPIå“åº”æ ¼å¼ä¸­æå–å†…å®¹"""
        if api_type == "ollama":
            if "message" in response_data and "content" in response_data["message"]:
                return response_data["message"]["content"]
        elif api_type == "openai":
            if "choices" in response_data and len(response_data["choices"]) > 0:
                return response_data["choices"][0]["message"]["content"]
        
        # é€šç”¨æ ¼å¼ï¼Œå°è¯•å„ç§å¯èƒ½çš„è·¯å¾„
        if "content" in response_data:
            return response_data["content"]
        elif "message" in response_data and "content" in response_data["message"]:
            return response_data["message"]["content"]
        elif "choices" in response_data and len(response_data["choices"]) > 0:
            if "message" in response_data["choices"][0]:
                return response_data["choices"][0]["message"]["content"]
            elif "text" in response_data["choices"][0]:
                return response_data["choices"][0]["text"]
        
        logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå–å†…å®¹")
        return ""
    
    def _extract_stream_chunk(self, chunk_data):
        """ä»æµå¼å“åº”æ•°æ®å—ä¸­æå–å†…å®¹"""
        # å°è¯•å„ç§å¯èƒ½çš„è·¯å¾„æå–å†…å®¹
        if "content" in chunk_data:
            return chunk_data["content"]
        elif "message" in chunk_data and "content" in chunk_data["message"]:
            return chunk_data["message"]["content"]
        elif "choices" in chunk_data and len(chunk_data["choices"]) > 0:
            if "delta" in chunk_data["choices"][0] and "content" in chunk_data["choices"][0]["delta"]:
                return chunk_data["choices"][0]["delta"]["content"]
            elif "text" in chunk_data["choices"][0]:
                return chunk_data["choices"][0]["text"]
        elif "response" in chunk_data:
            return chunk_data["response"]
            
        return ""

    def _handle_streaming_response(self, response, api_type="unknown"):
        """å¤„ç†æµå¼å“åº”"""
        full_response = ""
        
        # è®°å½•è°ƒè¯•ä¿¡æ¯
        logger.info("å¼€å§‹å¤„ç†æµå¼å“åº”")
        
        # ç›´æ¥åœ¨èŠå¤©ç•Œé¢åˆ›å»ºä¸€ä¸ªåŠ©æ‰‹æ¶ˆæ¯æ¡†
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            message_placeholder = st.empty()
            
            # è®¾ç½®åˆå§‹"æ€è€ƒä¸­"çŠ¶æ€
            message_placeholder.markdown(
                """<div style="display: flex; align-items: center; color: #aaa;">
                <div class="typing-dots">
                <span>.</span><span>.</span><span>.</span>
                </div>æ€è€ƒä¸­</div>""", 
                unsafe_allow_html=True
            )
            
            try:
                # å¤„ç†æµå¼å“åº”
                for line in response.iter_lines():
                    if not line:
                        continue
                    
                    # è§£ææ•°æ®è¡Œ
                    if line.startswith(b'data: '):
                        data = line[6:].decode('utf-8', errors='replace')
                        
                        if data.strip() == "[DONE]":
                            break
                        
                        # å°è¯•è§£æJSON
                        try:
                            chunk = json.loads(data)
                            
                            # æ ¹æ®ä¸åŒAPIç±»å‹æå–å†…å®¹
                            content = None
                            if api_type == "ollama":
                                if "message" in chunk and "content" in chunk["message"]:
                                    content = chunk["message"]["content"]
                                elif "response" in chunk:
                                    content = chunk["response"]
                            elif api_type == "openai":
                                if "choices" in chunk and len(chunk["choices"]) > 0:
                                    delta = chunk["choices"][0].get("delta", {})
                                    content = delta.get("content", "")
                            else:
                                # é€šç”¨æ ¼å¼è§£æ
                                content = self._extract_stream_chunk(chunk)
                            
                            if content:
                                full_response += content
                                # æ˜¾ç¤ºå…‰æ ‡æ•ˆæœ
                                message_placeholder.markdown(full_response + "â–Œ")
                        except json.JSONDecodeError:
                            logger.warning(f"JSONè§£æå¤±è´¥: {data[:100]}")
                        except Exception as e:
                            logger.error(f"å¤„ç†æ•°æ®å—æ—¶å‡ºé”™: {e}")
                    else:
                        # å¤„ç†æ²¡æœ‰data:å‰ç¼€çš„è¡Œ
                        try:
                            line_text = line.decode('utf-8', errors='replace')
                            
                            # å°è¯•è§£æä¸ºJSON
                            try:
                                chunk = json.loads(line_text)
                                content = self._extract_stream_chunk(chunk)
                                if content:
                                    full_response += content
                                    message_placeholder.markdown(full_response + "â–Œ")
                            except json.JSONDecodeError:
                                # ä¸æ˜¯JSONï¼Œå¯èƒ½æ˜¯æ™®é€šæ–‡æœ¬
                                if line_text and not line_text.startswith("{") and not line_text.startswith("["):
                                    full_response += line_text
                                    message_placeholder.markdown(full_response + "â–Œ")
                        except Exception as e:
                            logger.error(f"å¤„ç†éæ ‡å‡†è¡Œæ—¶å‡ºé”™: {e}")
                
                # æ˜¾ç¤ºæœ€ç»ˆç»“æœï¼ˆæ— å…‰æ ‡ï¼‰
                if full_response:
                    message_placeholder.markdown(full_response)
                else:
                    # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•å“åº”ï¼Œæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
                    message_placeholder.error("æœªæ”¶åˆ°æœ‰æ•ˆçš„å“åº”")
                    
            except Exception as e:
                # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                logger.error(f"å¤„ç†æµå¼å“åº”æ—¶å‡ºé”™: {e}", exc_info=True)
                message_placeholder.error(f"å¤„ç†å“åº”æ—¶å‡ºé”™: {str(e)}")
        
        return full_response 